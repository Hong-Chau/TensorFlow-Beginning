{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=5, micro=2, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120,4,setosa,versicolor,virginica\n",
      "6.4,2.8,5.6,2.2,2\n",
      "5.0,2.3,3.3,1.0,1\n",
      "4.9,2.5,4.5,1.7,2\n",
      "4.9,3.1,1.5,0.1,0\n",
      "5.7,3.8,1.7,0.3,0\n",
      "4.4,3.2,1.3,0.2,0\n",
      "5.4,3.4,1.5,0.4,0\n",
      "6.9,3.1,5.1,2.3,2\n",
      "6.7,3.1,4.4,1.4,1\n",
      "5.1,3.7,1.5,0.4,0\n",
      "5.2,2.7,3.9,1.4,1\n",
      "6.9,3.1,4.9,1.5,1\n",
      "5.8,4.0,1.2,0.2,0\n",
      "5.4,3.9,1.7,0.4,0\n",
      "7.7,3.8,6.7,2.2,2\n",
      "6.3,3.3,4.7,1.6,1\n",
      "6.8,3.2,5.9,2.3,2\n",
      "7.6,3.0,6.6,2.1,2\n",
      "6.4,3.2,5.3,2.3,2\n",
      "5.7,4.4,1.5,0.4,0\n",
      "6.7,3.3,5.7,2.1,2\n",
      "6.4,2.8,5.6,2.1,2\n",
      "5.4,3.9,1.3,0.4,0\n",
      "6.1,2.6,5.6,1.4,2\n",
      "7.2,3.0,5.8,1.6,2\n",
      "5.2,3.5,1.5,0.2,0\n",
      "5.8,2.6,4.0,1.2,1\n",
      "5.9,3.0,5.1,1.8,2\n",
      "5.4,3.0,4.5,1.5,1\n",
      "6.7,3.0,5.0,1.7,1\n",
      "6.3,2.3,4.4,1.3,1\n",
      "5.1,2.5,3.0,1.1,1\n",
      "6.4,3.2,4.5,1.5,1\n",
      "6.8,3.0,5.5,2.1,2\n",
      "6.2,2.8,4.8,1.8,2\n",
      "6.9,3.2,5.7,2.3,2\n",
      "6.5,3.2,5.1,2.0,2\n",
      "5.8,2.8,5.1,2.4,2\n",
      "5.1,3.8,1.5,0.3,0\n",
      "4.8,3.0,1.4,0.3,0\n",
      "7.9,3.8,6.4,2.0,2\n",
      "5.8,2.7,5.1,1.9,2\n",
      "6.7,3.0,5.2,2.3,2\n",
      "5.1,3.8,1.9,0.4,0\n",
      "4.7,3.2,1.6,0.2,0\n",
      "6.0,2.2,5.0,1.5,2\n",
      "4.8,3.4,1.6,0.2,0\n",
      "7.7,2.6,6.9,2.3,2\n",
      "4.6,3.6,1.0,0.2,0\n",
      "7.2,3.2,6.0,1.8,2\n",
      "5.0,3.3,1.4,0.2,0\n",
      "6.6,3.0,4.4,1.4,1\n",
      "6.1,2.8,4.0,1.3,1\n",
      "5.0,3.2,1.2,0.2,0\n",
      "7.0,3.2,4.7,1.4,1\n",
      "6.0,3.0,4.8,1.8,2\n",
      "7.4,2.8,6.1,1.9,2\n",
      "5.8,2.7,5.1,1.9,2\n",
      "6.2,3.4,5.4,2.3,2\n",
      "5.0,2.0,3.5,1.0,1\n",
      "5.6,2.5,3.9,1.1,1\n",
      "6.7,3.1,5.6,2.4,2\n",
      "6.3,2.5,5.0,1.9,2\n",
      "6.4,3.1,5.5,1.8,2\n",
      "6.2,2.2,4.5,1.5,1\n",
      "7.3,2.9,6.3,1.8,2\n",
      "4.4,3.0,1.3,0.2,0\n",
      "7.2,3.6,6.1,2.5,2\n",
      "6.5,3.0,5.5,1.8,2\n",
      "5.0,3.4,1.5,0.2,0\n",
      "4.7,3.2,1.3,0.2,0\n",
      "6.6,2.9,4.6,1.3,1\n",
      "5.5,3.5,1.3,0.2,0\n",
      "7.7,3.0,6.1,2.3,2\n",
      "6.1,3.0,4.9,1.8,2\n",
      "4.9,3.1,1.5,0.1,0\n",
      "5.5,2.4,3.8,1.1,1\n",
      "5.7,2.9,4.2,1.3,1\n",
      "6.0,2.9,4.5,1.5,1\n",
      "6.4,2.7,5.3,1.9,2\n",
      "5.4,3.7,1.5,0.2,0\n",
      "6.1,2.9,4.7,1.4,1\n",
      "6.5,2.8,4.6,1.5,1\n",
      "5.6,2.7,4.2,1.3,1\n",
      "6.3,3.4,5.6,2.4,2\n",
      "4.9,3.1,1.5,0.1,0\n",
      "6.8,2.8,4.8,1.4,1\n",
      "5.7,2.8,4.5,1.3,1\n",
      "6.0,2.7,5.1,1.6,1\n",
      "5.0,3.5,1.3,0.3,0\n",
      "6.5,3.0,5.2,2.0,2\n",
      "6.1,2.8,4.7,1.2,1\n",
      "5.1,3.5,1.4,0.3,0\n",
      "4.6,3.1,1.5,0.2,0\n",
      "6.5,3.0,5.8,2.2,2\n",
      "4.6,3.4,1.4,0.3,0\n",
      "4.6,3.2,1.4,0.2,0\n",
      "7.7,2.8,6.7,2.0,2\n",
      "5.9,3.2,4.8,1.8,1\n",
      "5.1,3.8,1.6,0.2,0\n",
      "4.9,3.0,1.4,0.2,0\n",
      "4.9,2.4,3.3,1.0,1\n",
      "4.5,2.3,1.3,0.3,0\n",
      "5.8,2.7,4.1,1.0,1\n",
      "5.0,3.4,1.6,0.4,0\n",
      "5.2,3.4,1.4,0.2,0\n",
      "5.3,3.7,1.5,0.2,0\n",
      "5.0,3.6,1.4,0.2,0\n",
      "5.6,2.9,3.6,1.3,1\n",
      "4.8,3.1,1.6,0.2,0\n",
      "6.3,2.7,4.9,1.8,2\n",
      "5.7,2.8,4.1,1.3,1\n",
      "5.0,3.0,1.6,0.2,0\n",
      "6.3,3.3,6.0,2.5,2\n",
      "5.0,3.5,1.6,0.6,0\n",
      "5.5,2.6,4.4,1.2,1\n",
      "5.7,3.0,4.2,1.2,1\n",
      "4.4,2.9,1.4,0.2,0\n",
      "4.8,3.0,1.4,0.1,0\n",
      "5.5,2.4,3.7,1.0,1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # If the training and test sets aren't stored locally, download them.\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.request.urlopen(IRIS_TRAINING_URL).read()\n",
    "    # print(raw)\n",
    "    print(raw.decode('utf-8'))\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "        f.write(raw.decode('utf-8'))\n",
    "\n",
    "if not os.path.exists(str(IRIS_TEST)):\n",
    "    raw = urllib.request.urlopen(IRIS_TEST_URL).read()\n",
    "#with open(IRIS_TEST, \"w\") as f:\n",
    "#    f.write(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f129bcbd0cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIRIS_TRAINING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       features_dtype=np.float32)\n\u001b[0m\u001b[1;32m      7\u001b[0m test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n\u001b[1;32m      8\u001b[0m       \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIRIS_TEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\u001b[0m in \u001b[0;36mload_csv_with_header\u001b[0;34m(filename, target_dtype, features_dtype, target_column)\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main() \n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  # Specify that all features have real-value data\n",
    "  feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_task_id': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_model_dir': '/tmp/iris_model', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd8075eee10>, '_master': '', '_task_type': None, '_num_worker_replicas': 0, '_session_config': None, '_environment': 'local', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[10, 20, 10],\n",
    "                                              n_classes=3,\n",
    "                                              model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99f85221895b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_train_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    951\u001b[0m       \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrib_framework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       \u001b[0mmodel_fn_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4544003366da>\u001b[0m in \u001b[0;36mget_train_inputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the training inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_train_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "  # Fit model.\n",
    "classifier.fit(input_fn=get_train_inputs, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
